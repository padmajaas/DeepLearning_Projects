{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Lambda,Conv1D, MaxPooling1D,Activation, Dense,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_AUDIO_DIR= './Padmaja/EdvancerClass/DeepLearning/Project2MusicGenreIdentification/audio'\n",
    "TARGET_SR=8000\n",
    "OUTPUT_DIR='./Padmaja/EdvancerClass/DeepLearning/Project2MusicGenreIdentification/output'\n",
    "OUTPUT_DIR_TRAIN= os.path.join(OUTPUT_DIR,\"train\")\n",
    "OUTPUT_DIR_TEST=os.path.join(OUTPUT_DIR,\"test\")\n",
    "AUDIO_LENGTH=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/Padmaja/EdvancerClass/DeepLearning/Project2MusicGenreIdentification/output/train')\n",
    "os.makedirs('/Padmaja/EdvancerClass/DeepLearning/Project2MusicGenreIdentification/output/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids={\n",
    "    'blues':0,\n",
    "    'classical':1,\n",
    "    'country':2,\n",
    "    'disco':3,\n",
    "    'hiphop':4,\n",
    "    'jazz':5,\n",
    "    'metal':6,\n",
    "    'pop':7,\n",
    "    'reggae':8,\n",
    "    'rock':9    \n",
    "}\n",
    "def extract_class_id(wav_filename):\n",
    "    if 'blues' in wav_filename:\n",
    "        return class_ids.get('blues')\n",
    "    elif 'classical' in wav_filename:\n",
    "        return class_ids.get('classical')\n",
    "    elif 'country' in wav_filename:\n",
    "        return class_ids.get('country')\n",
    "    elif 'disco' in wav_filename:\n",
    "        return class_ids.get('disco')\n",
    "    elif 'hiphop' in wav_filename:\n",
    "        return class_ids.get('hiphop')\n",
    "    elif 'jazz' in wav_filename:\n",
    "        return class_ids.get('jazz')\n",
    "    elif 'metal' in wav_filename:\n",
    "        return class_ids.get('metal')\n",
    "    elif 'pop' in wav_filename:\n",
    "        return class_ids.get('pop')\n",
    "    elif 'reggae' in wav_filename:\n",
    "        return class_ids.get('reggae')\n",
    "    elif 'rock' in wav_filename:\n",
    "        return class_ids.get('rock')\n",
    "    else:\n",
    "        return class_ids.get('unlabelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio_from_filename(filename, target_sr):\n",
    "    audio, _ = librosa.load(filename, sr=target_sr, mono=True)\n",
    "    audio = audio.reshape(-1, 1)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data():\n",
    "    for i, wav_filename in enumerate(iglob(os.path.join(DATA_AUDIO_DIR, '**/**.wav'), recursive=True)):\n",
    "        class_id = extract_class_id(wav_filename)\n",
    "        audio_buf = read_audio_from_filename(wav_filename, target_sr=TARGET_SR)\n",
    "        # normalize mean 0, variance 1\n",
    "        audio_buf = (audio_buf - np.mean(audio_buf)) / np.std(audio_buf)\n",
    "        original_length = len(audio_buf)\n",
    "        print(i, wav_filename, original_length, np.round(np.mean(audio_buf), 4), np.std(audio_buf))\n",
    "        if original_length < AUDIO_LENGTH:\n",
    "            audio_buf = np.concatenate((audio_buf, np.zeros(shape=(AUDIO_LENGTH - original_length, 1))))\n",
    "            print('PAD New length =', len(audio_buf))\n",
    "        elif original_length > AUDIO_LENGTH:\n",
    "            audio_buf = audio_buf[0:AUDIO_LENGTH]\n",
    "            print('CUT New length =', len(audio_buf))\n",
    "\n",
    "        output_folder = OUTPUT_DIR_TRAIN\n",
    "        if i // 10 == 0:\n",
    "            output_folder = OUTPUT_DIR_TEST\n",
    "\n",
    "        output_filename = os.path.join(output_folder, str(i) + '.pkl')\n",
    "\n",
    "        out = {'class_id': class_id,\n",
    "               'audio': audio_buf,\n",
    "               'sr': TARGET_SR}\n",
    "        w=open(output_filename,'wb')\n",
    "        pickle.dump(out,w)\n",
    "        w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m5(num_classes=5):\n",
    "    print(\"Using model M5:\")\n",
    "    m=Sequential()\n",
    "    m.add(Conv1D(128,\n",
    "                input_shape=[AUDIO_LENGTH,1],\n",
    "               kernel_size=80,\n",
    "               strides=4,\n",
    "               padding='same',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4,strides=None))\n",
    "    m.add(Conv1D(128,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                padding='same',\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4,strides=None))\n",
    "    m.add(Conv1D(256,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                padding='same',\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4,strides=None))\n",
    "    m.add(Conv1D(512,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                padding='same',\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(l=0.0001)))\n",
    "    m.add(BatchNormalization())\n",
    "    m.add(Activation('relu'))\n",
    "    m.add(MaxPooling1D(pool_size=4,strides=None))\n",
    "    m.add(Lambda(lambda x: K.mean(x, axis=1)))   # Same as GAP for 1D Conv Layer\n",
    "    m.add(Dense(num_classes, activation='softmax'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_list):\n",
    "    def load_into(_filename, _x, _y):\n",
    "        with open(_filename, 'rb') as f:\n",
    "            audio_element=pickle.load(f)\n",
    "            _x.append(audio_element['audio'])\n",
    "            _y.append(audio_element['class_id'])\n",
    "            \n",
    "    x, y = [], []\n",
    "    for filename in file_list:\n",
    "        load_into(filename,x,y)\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model M5:\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 2500, 128)         10368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 2500, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2500, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 625, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 625, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 625, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 625, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 156, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 156, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 156, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 156, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 39, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 39, 512)           393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 39, 512)           2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 39, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 558,597\n",
      "Trainable params: 556,549\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n",
      "x_tr.shape = (0,)\n",
      "y_tr.shape = (0, 5)\n",
      "x_te.shape = (0,)\n",
      "y_te.shape = (0, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_16_input to have 3 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-a1c7705cad52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m           validation_data=(x_te, y_te))   #callbacks=[reduce_lr]\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv1d_16_input to have 3 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "num_classes=5\n",
    "model = m5(num_classes=num_classes)\n",
    "\n",
    "if model is None:\n",
    "    exit(\"Something went wrong!!\")\n",
    "    \n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "train_files = glob(os.path.join(OUTPUT_DIR_TRAIN, '**.pkl'))\n",
    "x_tr, y_tr = get_data(train_files)\n",
    "y_tr = to_categorical(y_tr, num_classes=num_classes)\n",
    "\n",
    "test_files = glob(os.path.join(OUTPUT_DIR_TEST, '**.pkl'))\n",
    "x_te, y_te = get_data(test_files)\n",
    "y_te = to_categorical(y_te, num_classes=num_classes)\n",
    "\n",
    "print('x_tr.shape =', x_tr.shape)\n",
    "print('y_tr.shape =', y_tr.shape)\n",
    "print('x_te.shape =', x_te.shape)\n",
    "print('y_te.shape =', y_te.shape)\n",
    "\n",
    "# if the accuracy does not increase over 10 epochs, reduce the learning rate by half.\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
    "batch_size = 128\n",
    "model.fit(x=x_tr,\n",
    "          y=y_tr,\n",
    "          batch_size=batch_size,\n",
    "          epochs=400,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          validation_data=(x_te, y_te))   #callbacks=[reduce_lr]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
